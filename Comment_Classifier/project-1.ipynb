{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use path to file here...I like absolute path to minimize errors\n",
    "file = \"/home/nyangweso/Desktop/Ds_1/Machine-Learning-Projects/Comment_Classifier/data/Books_small_10000.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use classes to store the details and help make the code look cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A C like enum class\n",
    "class Sentiment:\n",
    "    NEG = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POS = \"POSITIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self, comment, rating) -> None:\n",
    "        self.comment = comment\n",
    "        self.rating = rating\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.rating <= 2:\n",
    "            return Sentiment.NEG\n",
    "        elif self.rating == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            return Sentiment.POS\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewContainer:\n",
    "    def __init__(self, reviews) -> None:\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_text(self):\n",
    "        return [a.comment for a in self.reviews]\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        return [a.sentiment for a in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment ==\n",
    "                        Sentiment.NEG, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment ==\n",
    "                        Sentiment.POS, self.reviews))\n",
    "        positive_shrunk = positive[: len(negative)]\n",
    "\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "\n",
    "        print(len(negative), len(positive_shrunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        reviews.append(Review(data[\"reviewText\"], data[\"overall\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access a single comment and rating, and its sentiment\n",
    "n = 68\n",
    "print(\n",
    "    f\"{reviews[n].comment} \\nRating = {reviews[n].rating} \\nRating is {reviews[n].sentiment}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cont = ReviewContainer(training)\n",
    "test_cont = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test) / len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cont.evenly_distribute()\n",
    "test_cont.evenly_distribute()\n",
    "\n",
    "\n",
    "# Training models\n",
    "train_x = train_cont.get_text()\n",
    "train_y = train_cont.get_sentiment()\n",
    "\n",
    "\n",
    "# Test models\n",
    "test_x = test_cont.get_text()\n",
    "test_y = test_cont.get_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y.count(Sentiment.POS), train_y.count(Sentiment.NEG))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bags Of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "# We only need to transform our test data...no fitting like in train data\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a model to work with from 'train_x_vectors' and 'train_y'.<br>\n",
    "But 1st lets look at some models inorder for us to know the best option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Model Selection and Classification</u>\n",
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets leave this sentiment here for checking\n",
    "test_y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisrt create a SVC classifier object\n",
    "cls_svm = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "# Then fit the classifier into the model using the _.fit method\n",
    "cls_svm.fit(train_x_vectors, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can use the .predict method on our test data to see if it can predict\n",
    "# We use the vectorized test data 'test_x_vectors' to see if our classifer can predict\n",
    "cls_svm.predict(test_x_vectors[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dec = DecisionTreeClassifier()\n",
    "cls_dec.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dec.predict(test_x_vectors[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Naive Bayes (Gaussian Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_gnb = GaussianNB()\n",
    "# cls_gnb.fit(train_x_vectors.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_gnb.predict(test_x_vectors[3].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_log = LogisticRegression(max_iter=1000)\n",
    "cls_log.fit(train_x_vectors, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_log.predict(test_x_vectors[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Now that we've created sample models, lets see how well each model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Accuracy\n",
    "print(f\"Support Vector Machine = {cls_svm.score(test_x_vectors, test_y)}\")\n",
    "print(f\"Decision Tree = {cls_dec.score(test_x_vectors, test_y)}\")\n",
    "# print(f\"Gaussian Naive Bayes = {cls_gnb.score(test_x_vectors.toarray(), test_y)}\")\n",
    "print(f\"Logistic Regression = {cls_log.score(test_x_vectors, test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see mean-wise svm and logistic look like they're good models overally \\\n",
    "Lets look at the F1 score also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick function\n",
    "def f1_score_calculator(y_true, y_pred):\n",
    "    arr = f1_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=None,\n",
    "        labels=[Sentiment.POS, Sentiment.NEUTRAL, Sentiment.NEG],\n",
    "    )\n",
    "    return f\"   {Sentiment.POS} = {arr[0] * 100: .2f},     {Sentiment.NEUTRAL} = {arr[1] * 100: .2f},      {Sentiment.NEG} = {arr[2] * 100: .2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 scores\n",
    "print(\n",
    "    f\"Support Vector Machine f1 score >> {f1_score_calculator(test_y, cls_svm.predict(test_x_vectors))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Decision Tree f1 score >> {f1_score_calculator(test_y, cls_dec.predict(test_x_vectors))}\"\n",
    ")\n",
    "# print(f\"Gaussian Naive Bayes f1 score >> {f1_score_calculator(test_y, cls_gnb.predict(test_x_vectors.toarray()))}\")\n",
    "print(\n",
    "    f\"Logistic Regression f1 score >> {f1_score_calculator(test_y, cls_log.predict(test_x_vectors))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = [\"I loved this book! The characters were so well-developed and the plot kept me on the edge of my seat.\",\n",
    "                 \"This book was a disappointment. The writing was poor and the story was predictable.\",\n",
    "                 \"I couldn't put this book down! It was a real page-turner.\",\n",
    "                 \"The ending of this book left me feeling unsatisfied. It felt rushed and incomplete.\",\n",
    "                 \"The world-building in this book was incredible. I felt like I was really there.\",\n",
    "                 \"I found this book to be boring and uneventful. I struggled to finish it.\",\n",
    "                 \"The dialogue in this book was so natural and realistic. It really brought the characters to life.\",\n",
    "                 \"This book had too many plot holes and inconsistencies for me to enjoy it.\",\n",
    "                 \"The pacing of this book was perfect. It kept me engaged from start to finish.\",\n",
    "                 \"I didn't connect with any of the characters in this book. They all felt flat and one-dimensional.\"]\n",
    "\n",
    "new_test = vectorizer.transform(new_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, comment in enumerate(new_test_data):\n",
    "    print(f'{comment} >>    {cls_log.predict(new_test)[count]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, comment in enumerate(new_test_data):\n",
    "    print(f'{comment} >>    {cls_dec.predict(new_test)[count]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, comment in enumerate(new_test_data):\n",
    "    print(f'{comment} >>    {cls_svm.predict(new_test)[count]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning our model using <b>Grid Search</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel' : ('linear', 'rbf'), 'C' : (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, param_grid=parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Support Vector Machine = {clf.score(test_x_vectors, test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the same dataset, our model improved by 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Our Model\n",
    "We save our model so that we don't have to retrain it the next time we're using it using the pickle library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = \"/home/nyangweso/Desktop/Ds_1/Machine-Learning-Projects/Category_Classifier/models/sentiment_classifier.pkl\"\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, 'rb') as f:\n",
    "    loaded_clf = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
