{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a simple classifier algorithm e.g k-neighbours and use it to explain the various approaches in model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Model Validation - Naive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, y_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an accuracy score of 1.0...but this brings out a fundamental flaw:\\\n",
    "<i>if it trains and evaluates the model on the same data, accuracy will always be 100%</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model Validation the right way : Use of holdout sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a holdout set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0, train_size=0.5)\n",
    "\n",
    "model.fit(X1, y1)\n",
    "\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of holdout sets brings out a more reasonable result as seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model Validation via cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. Two-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. n-fold cross validation e.g n=5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Getting average...\n",
    "scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def polynomial_regression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_data(N, err=1.0, rseed=1):\n",
    "    # Randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1.0 / (X.ravel() + 0.1)\n",
    "\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = make_data(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()  # plot formatting\n",
    "\n",
    "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = polynomial_regression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they are different polynomials for the above model, we can make progress by visualizing the validation curve\\\n",
    "for this data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_curve?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "degree = np.arange(0, 21)\n",
    "\n",
    "train_score, val_score = validation_curve(\n",
    "    estimator=polynomial_regression(),\n",
    "    X=X,\n",
    "    y=y,\n",
    "    param_name=\"polynomialfeatures__degree\",\n",
    "    param_range=degree,\n",
    "    cv=7,\n",
    ")\n",
    "\n",
    "plt.plot(degree, np.median(train_score, 1),\n",
    "         color=\"blue\", label=\"training score\")\n",
    "plt.plot(degree, np.median(val_score, 1),\n",
    "         color=\"red\", label=\"validation score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the validation curve above, we see the optimum trade-off is at degree = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = polynomial_regression(3).fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test)\n",
    "plt.axis(lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = make_data(200)\n",
    "plt.scatter(X2.ravel(), y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.arange(21)\n",
    "\n",
    "train_score2, val_score2 = validation_curve(\n",
    "    estimator=polynomial_regression(),\n",
    "    X=X2,\n",
    "    y=y2,\n",
    "    param_name=\"polynomialfeatures__degree\",\n",
    "    param_range=degree,\n",
    "    cv=7,\n",
    ")\n",
    "\n",
    "plt.plot(degree, np.median(train_score2, 1),\n",
    "         color=\"blue\", label=\"training score\")\n",
    "plt.plot(degree, np.median(val_score2, 1),\n",
    "         color=\"red\", label=\"validation score\")\n",
    "plt.plot(degree, np.median(train_score, 1),\n",
    "         color=\"blue\", alpha=0.3, linestyle=\"dashed\")\n",
    "plt.plot(degree, np.median(val_score, 1),\n",
    "         color=\"red\", alpha=0.3, linestyle=\"dashed\")\n",
    "plt.legend(loc=\"lower center\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Validation curve above, the solid lines show the new results, while the fainter dashed lines show the results of the previous smaller dataset\\\n",
    "To compute a learning curve, use the learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "for i, degree in enumerate([2, 9]):\n",
    "    N, train_lc, val_lc = learning_curve(\n",
    "        polynomial_regression(degree), X, y, cv=7, train_sizes=np.linspace(0.3, 1, 25)\n",
    "    )\n",
    "    ax[i].plot(N, np.mean(train_lc, 1), color=\"blue\", label=\"training score\")\n",
    "    ax[i].plot(N, np.mean(val_lc, 1), color=\"red\", label=\"validation score\")\n",
    "    ax[i].hlines(\n",
    "        np.mean([train_lc[-1], val_lc[-1]]),\n",
    "        N[0],\n",
    "        N[-1],\n",
    "        color=\"gray\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    ax[i].set_ylim(0, 1)\n",
    "    ax[i].set_xlim(N[0], N[-1])\n",
    "    ax[i].set_xlabel(\"training size\")\n",
    "    ax[i].set_ylabel(\"score\")\n",
    "    ax[i].set_title(\"degree = {0}\".format(degree), size=14)\n",
    "    ax[i].legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curves above for a low-complexity model (left) and a high-complexity model (right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Validation in Practice: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
