{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the commented MAX_DISTANCE_FROM_PROTOTYPE and MAX_CLUSTER_DISTANCE takes a long time to run\n",
    "\n",
    "# MAX_DISTANCE_FROM_PROTOTYPE = .01\n",
    "\n",
    "# MAX_CLUSTER_DISTANCE = .7\n",
    "\n",
    "MAX_DISTANCE = 5000\n",
    "\n",
    "\n",
    "MAX_DISTANCE_FROM_PROTOTYPE = .1\n",
    "\n",
    "MAX_CLUSTER_DISTANCE = .8\n",
    "\n",
    "\n",
    "class ClusterNode(object):\n",
    "\n",
    "    def __init__(self, data_point, nearest_prototype_cluster_node=None):\n",
    "        # data point\n",
    "        self._data_point = data_point\n",
    "\n",
    "        self._assigned_cluster = None\n",
    "\n",
    "        # prototype node this node is associated with;\n",
    "        self._nearest_prototype_cluster_node = nearest_prototype_cluster_node\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(node_a, node_b):\n",
    "        node_a_data_point = node_a.data_point\n",
    "        node_b_data_point = node_b.data_point\n",
    "\n",
    "        distance = 0\n",
    "\n",
    "        distance = np.sqrt(\n",
    "            np.sum(np.square(node_a_data_point - node_b_data_point)))\n",
    "\n",
    "        return distance\n",
    "\n",
    "    @staticmethod\n",
    "    def similarity(node_a, node_b):\n",
    "        return 1 / (1 + ClusterNode.distance(node_a, node_b))\n",
    "\n",
    "    @property\n",
    "    def assigned_cluster(self):\n",
    "        \"\"\"\n",
    "         Cluster that this node belongs to\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self._assigned_cluster\n",
    "\n",
    "    @assigned_cluster.setter\n",
    "    def assigned_cluster(self, value):\n",
    "        self._assigned_cluster = value\n",
    "\n",
    "    @property\n",
    "    def cluster_id(self):\n",
    "        if self._assigned_cluster is None:\n",
    "            return None\n",
    "\n",
    "        return self._assigned_cluster.cluster_id\n",
    "\n",
    "    @property\n",
    "    def is_prototype(self):\n",
    "        return self == self._nearest_prototype_cluster_node\n",
    "\n",
    "    @property\n",
    "    def data_point(self):\n",
    "        return self._data_point\n",
    "\n",
    "    @property\n",
    "    def nearest_prototype_cluster_node(self):\n",
    "        return self._nearest_prototype_cluster_node\n",
    "\n",
    "    @nearest_prototype_cluster_node.setter\n",
    "    def nearest_prototype_cluster_node(self, value):\n",
    "        self._nearest_prototype_cluster_node = value\n",
    "\n",
    "\n",
    "class Cluster(object):\n",
    "\n",
    "    def __init__(self, cluster_node_list=[]):\n",
    "\n",
    "        self._cluster_id = id(self)\n",
    "\n",
    "        self._cluster_node_list = []\n",
    "\n",
    "        for cluster_node in cluster_node_list:\n",
    "            self.add_node_to_cluster(cluster_node)\n",
    "\n",
    "    def add_node_to_cluster(self, cluster_node):\n",
    "\n",
    "        # Update node's cluster assignment\n",
    "        cluster_node.assigned_cluster = self\n",
    "\n",
    "        # Add node to cluster's node list\n",
    "        self._cluster_node_list.append(cluster_node)\n",
    "\n",
    "    def merge_cluster(self, cluster_2_merge):\n",
    "\n",
    "        for cluster_2_merge_node in cluster_2_merge.cluster_nodes:\n",
    "            self.add_node_to_cluster(cluster_2_merge_node)\n",
    "\n",
    "    @property\n",
    "    def cluster_nodes(self):\n",
    "\n",
    "        for cluster_node in self._cluster_node_list:\n",
    "            yield cluster_node\n",
    "\n",
    "    @staticmethod\n",
    "    def complete_linkage_distance(cluster_a, cluster_b):\n",
    "        \"\"\"\n",
    "         Computes the complete linkage distance of two clusters\n",
    "        :param cluster_a:\n",
    "        :param cluster_b:\n",
    "        :return: \n",
    "        \"\"\"\n",
    "\n",
    "        # Note: Complete linkage computes the maximum distance of a pair of nodes from cluster a\n",
    "        #       and cluster b\n",
    "\n",
    "        max_distance = 0\n",
    "\n",
    "        for node_a in cluster_a._cluster_node_list:\n",
    "            for node_b in cluster_b._cluster_node_list:\n",
    "                # Computing the distance between the current nodes\n",
    "                distance = ClusterNode.distance(node_a=node_a, node_b=node_b)\n",
    "\n",
    "                # If this is the largest found so far update max_distance\n",
    "                max_distance = max(max_distance, distance)\n",
    "\n",
    "        return max_distance\n",
    "\n",
    "    @property\n",
    "    def cluster_id(self):\n",
    "        return self._cluster_id\n",
    "\n",
    "\n",
    "class ApproxAgglomerativeClustering(object):\n",
    "\n",
    "    def __init__(self, data_set=None):\n",
    "\n",
    "        self._data_set = data_set\n",
    "\n",
    "        self._cluster_node_list = []\n",
    "\n",
    "        self._cluster_list = []\n",
    "\n",
    "    def load_dataset_from_file(self, file_path):\n",
    "\n",
    "        # Load the dataset from file\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "        # get all of the points from the dataset as an array of n-dimensional vectors\n",
    "        X = df.iloc[:].values\n",
    "\n",
    "        # Standardize the data set\n",
    "        X_std = np.copy(X)\n",
    "        X_std[:, 0] = (X_std[:, 0] - X_std[:, 0].mean()) / (X_std[:, 0].std())\n",
    "        X_std[:, 1] = (X_std[:, 1] - X_std[:, 1].mean()) / (X_std[:, 1].std())\n",
    "\n",
    "        self._data_set = X_std\n",
    "\n",
    "        # Create the cluster node list\n",
    "        self._cluster_node_list = [ClusterNode(\n",
    "            data_point) for data_point in self._data_set]\n",
    "\n",
    "        return self._cluster_node_list\n",
    "\n",
    "    def perform_clustering(self):\n",
    "\n",
    "        # Step 1: Determine the prototypes\n",
    "        prototype_list = self._get_prototypes()\n",
    "\n",
    "        # Step 2: Cluster Prototypes\n",
    "        self._cluster_list = self.cluster_nodes(prototype_list)\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        number_nodes = len(self._cluster_node_list)\n",
    "\n",
    "        # Step 3: Propagate Cluster assignments to nearest prototype\n",
    "        for cluster_node in self._cluster_node_list:\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if cluster_node.is_prototype:\n",
    "                continue\n",
    "\n",
    "            # Get cluster assignment from nearest prototype\n",
    "            nearest_prototype_assigned_cluster = cluster_node.nearest_prototype_cluster_node.assigned_cluster\n",
    "\n",
    "            # Add cluster node to cluster\n",
    "            nearest_prototype_assigned_cluster.add_node_to_cluster(\n",
    "                cluster_node)\n",
    "\n",
    "            if counter % 10 == 0:\n",
    "                print(\"\\n[ {}/{} ] Cluster node {} assigned to cluster {}\".format(counter, number_nodes,\n",
    "                                                                                  repr(\n",
    "                                                                                      cluster_node.data_point),\n",
    "                                                                                  nearest_prototype_assigned_cluster.cluster_id))\n",
    "\n",
    "    def cluster_nodes(self, cluster_node_list):\n",
    "\n",
    "        # Note: Initially, every cluster node is its own cluster in agglomerative hierarchical clustering\n",
    "        cluster_list = [Cluster([cluster_node])\n",
    "                        for cluster_node in cluster_node_list]\n",
    "\n",
    "        while True:\n",
    "\n",
    "            print(\"\\n**** Current number of clusters: {}*****\".format(len(cluster_list)))\n",
    "\n",
    "            # Step 1: Compute distances of the clusters\n",
    "            cluster_distance_dict = self._compute_cluster_distances(\n",
    "                cluster_list)\n",
    "\n",
    "            # Step 2:  Get the minimum cluster distances\n",
    "\n",
    "            (min_cluster_pair, min_cluster_distance_value) = self.get_min_cluster_distance(\n",
    "                cluster_distance_dict)\n",
    "\n",
    "            if len(min_cluster_pair) <= 1:\n",
    "                logger.warning(\"get_min_cluster_distance() has not been implemented correctly. Expecting a tuple of size 2\"\n",
    "                               \"where the elements of the tuple are the two clusters that have the minimum distance\")\n",
    "\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                \"Minimum Distance of {} is between current cluster {} and cluster {}\".format(min_cluster_distance_value,\n",
    "                                                                                             min_cluster_pair[\n",
    "                                                                                                 0].cluster_id,\n",
    "                                                                                             min_cluster_pair[\n",
    "                                                                                                 1].cluster_id))\n",
    "\n",
    "            if min_cluster_distance_value >= MAX_CLUSTER_DISTANCE:\n",
    "                break\n",
    "\n",
    "            # Step 3: Merge the min pair clusters\n",
    "            min_cluster_a = min_cluster_pair[0]\n",
    "            min_cluster_b = min_cluster_pair[1]\n",
    "\n",
    "            min_cluster_a.merge_cluster(min_cluster_b)\n",
    "\n",
    "            print(\"Merging cluster {} into cluster {}; Distance: {}\".format(min_cluster_b.cluster_id,\n",
    "                                                                            min_cluster_a.cluster_id,\n",
    "                                                                            min_cluster_distance_value))\n",
    "            cluster_list.remove(min_cluster_b)\n",
    "\n",
    "        return cluster_list\n",
    "\n",
    "    def _compute_cluster_distances(self, cluster_list):\n",
    "\n",
    "        cluster_distance_dict = dict()\n",
    "        for cluster_a in cluster_list:\n",
    "\n",
    "            cluster_distance_dict[cluster_a] = {}\n",
    "\n",
    "            for cluster_b in cluster_list:\n",
    "                distance = Cluster.complete_linkage_distance(\n",
    "                    cluster_a, cluster_b)\n",
    "\n",
    "                # print(\"Distance between current cluster {} and cluster {} is {}\".format(cluster_a.cluster_id,\n",
    "                #                                                                         cluster_b.cluster_id,\n",
    "                #                                                                         distance))\n",
    "                cluster_distance_dict[cluster_a][cluster_b] = distance\n",
    "\n",
    "        return cluster_distance_dict\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        num_clusters = len(self._cluster_list)\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure()\n",
    "        colors = cm.rainbow(np.linspace(0, 1, num_clusters))\n",
    "\n",
    "        cluster_index = 0\n",
    "\n",
    "        for color, cluster in zip(colors, self._cluster_list):\n",
    "\n",
    "            X = []\n",
    "            Y = []\n",
    "\n",
    "            for cluster_node in cluster.cluster_nodes:\n",
    "                x = cluster_node.data_point[0]\n",
    "                y = cluster_node.data_point[1]\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "            plt.scatter(X, Y, s=50, c=color, marker='o',\n",
    "                        label=\"cluster {}\".format(cluster_index + 1))\n",
    "            cluster_index += 1\n",
    "\n",
    "        plt.legend(scatterpoints=1)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _get_prototypes(self):\n",
    "\n",
    "        prototype_set = set()\n",
    "\n",
    "        prototype_distance_map = dict()\n",
    "\n",
    "        # Initalize prototype distance map, where the key is the prototype and the\n",
    "        # value is that prototypes distance.\n",
    "        # Note: The distance will be initialized to MAX_DISTANCE, which is the maximum distance\n",
    "        prototype_distance_map = {key: value for (key, value) in\n",
    "                                  [(cluster_node, MAX_DISTANCE) for cluster_node in self._cluster_node_list]}\n",
    "\n",
    "        pass\n",
    "\n",
    "        (curr_max_distance_cluster_node, current_max_distance_value) = self.compute_max_distance_from_prototype(\n",
    "            prototype_distance_map)\n",
    "        while True:\n",
    "\n",
    "            print(\"\\nCurrent max distance: {}\".format(\n",
    "                current_max_distance_value))\n",
    "\n",
    "            # All of the elements are less than 'MAX_DISTANCE_FROM_PROTOTYPE' away from a prototype\n",
    "            if current_max_distance_value < MAX_DISTANCE_FROM_PROTOTYPE:\n",
    "                break\n",
    "\n",
    "            for cluster_node in self._cluster_node_list:\n",
    "\n",
    "                if cluster_node == curr_max_distance_cluster_node or cluster_node in prototype_set:\n",
    "                    continue\n",
    "\n",
    "                # if the current distance from a prototype is greater than that of the curr_max_distance_analysis_report,\n",
    "                # then we'll use the curr_max_distance_analysis_reports distance\n",
    "                dist_from_curr_max_dist_cluster_node = ClusterNode.distance(curr_max_distance_cluster_node,\n",
    "                                                                            cluster_node)\n",
    "\n",
    "                if prototype_distance_map[cluster_node] > dist_from_curr_max_dist_cluster_node:\n",
    "                    prototype_distance_map[cluster_node] = dist_from_curr_max_dist_cluster_node\n",
    "\n",
    "                    # update the clusters  nodes nearest prototype\n",
    "                    cluster_node.nearest_prototype_cluster_node = curr_max_distance_cluster_node\n",
    "\n",
    "            # The current prototype candidate is its own prototype\n",
    "            curr_max_distance_cluster_node.nearest_prototype_cluster_node = curr_max_distance_cluster_node\n",
    "\n",
    "            # Add the current_prototype candidate to the prototype list\n",
    "            prototype_set.add(curr_max_distance_cluster_node)\n",
    "\n",
    "            print(\"(Current total:{}) Added the following cluster node as prototype: {}\".format(len(prototype_set),\n",
    "                                                                                                curr_max_distance_cluster_node.data_point))\n",
    "\n",
    "            # Since the candidate is a prototype, its distance to a prototype is 0 because it is a prototype\n",
    "            prototype_distance_map[curr_max_distance_cluster_node] = 0\n",
    "\n",
    "            # Find the next potential prototype candidate\n",
    "            (curr_max_distance_cluster_node, current_max_distance_value) = self.compute_max_distance_from_prototype(\n",
    "                prototype_distance_map)\n",
    "\n",
    "        return prototype_set\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_max_distance_from_prototype(prototype_distance_map):\n",
    "        \"\"\" Returns (key, value) tuple where the value is the max value in dictionary\n",
    "\n",
    "        :param prototype_distance_map:\n",
    "        :return: (key, value) tuple where the value is the max value in dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        max_distance = max(prototype_distance_map.items(),\n",
    "                           key=operator.itemgetter(1))\n",
    "\n",
    "        return max_distance\n",
    "\n",
    "    @staticmethod\n",
    "    def get_min_cluster_distance(cluster_distance_dict):\n",
    "        \"\"\"\n",
    "        :param cluster_distance_dict: 2-dimmensional dictionary that stores the distance of a pair of cluster nodes\n",
    "                                      Example: To retrieve the distance of cluster_a and cluster_b, do the following:\n",
    "                                               cluster_distance = cluster_distance_dict[cluster_a][cluster_b]\n",
    "\n",
    "        :return: A tuple, where the first element of tuple is itself a tuple of the pair of clusters who have the smallest distance.\n",
    "                 The second element of tuple is the distance of those two tuples\n",
    "        \"\"\"\n",
    "\n",
    "        # Setting initial value to +ve infinity\n",
    "        min_cluster_distance = float('inf')\n",
    "\n",
    "        min_cluster_pair = ()\n",
    "\n",
    "        for cluster_a, distances in cluster_distance_dict.items():\n",
    "            for cluster_b, dist in distances.items():\n",
    "                # skip duplicates\n",
    "                if cluster_a == cluster_b:\n",
    "                    continue\n",
    "\n",
    "                if min_cluster_distance > dist:\n",
    "                    min_cluster_pair = (cluster_a, cluster_b)\n",
    "                    min_cluster_distance = dist\n",
    "\n",
    "        return (min_cluster_pair, min_cluster_distance)\n",
    "\n",
    "    @property\n",
    "    def cluster_list(self):\n",
    "        return self._cluster_list\n",
    "\n",
    "\n",
    "def test_harness():\n",
    "    approx_clustering = ApproxAgglomerativeClustering()\n",
    "\n",
    "    # Load the dataset\n",
    "    approx_clustering.load_dataset_from_file(\n",
    "        \"lab1b/lab1bsamples_large.csv\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    approx_clustering.perform_clustering()\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(\"\\nRuntime: {} seconds\".format(elapsed_time))\n",
    "\n",
    "    approx_clustering.plot()\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_CLUSTERS = 50\n",
    "\n",
    "\n",
    "def elbow_method_plot(X):\n",
    "\n",
    "    sse = {}\n",
    "    for k in range(1, MAX_NUMBER_OF_CLUSTERS):\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=1000).fit(X)\n",
    "\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        sse[k] = kmeans.inertia_\n",
    "\n",
    "        if k > 1:\n",
    "\n",
    "            sil_coeff = silhouette_score(X, labels, metric='euclidean')\n",
    "\n",
    "            print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(\n",
    "                k, sil_coeff))\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(list(sse.keys()), list(sse.values()))\n",
    "\n",
    "    plt.xlabel(\"Number of cluster\")\n",
    "\n",
    "    plt.ylabel(\"SSE\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def perform_k_means_clustering(X, num_clusters):\n",
    "    # Initialize KMeans\n",
    "    km = KMeans(n_clusters=num_clusters,\n",
    "                init='k-means++',\n",
    "                n_init=10,\n",
    "                max_iter=300,\n",
    "                tol=1e-04,\n",
    "                random_state=0)\n",
    "\n",
    "    # Perform the clustering\n",
    "    start_time = time.time()\n",
    "    y_km = km.fit_predict(X)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Runtime: {} seconds\".format(elapsed_time))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure()\n",
    "    colors = cm.rainbow(np.linspace(0, 1, num_clusters))\n",
    "    for k, color in zip(range(num_clusters), colors):\n",
    "\n",
    "        # plot points for cluster i\n",
    "        plt.scatter(X[y_km == k, 0],\n",
    "                    X[y_km == k, 1],\n",
    "                    s=50,\n",
    "                    c=color,\n",
    "                    marker='o',\n",
    "                    label=\"cluster {}\".format(k+1))\n",
    "\n",
    "    plt.scatter(km.cluster_centers_[:, 0],\n",
    "                km.cluster_centers_[:, 1],\n",
    "                s=250,\n",
    "                marker='*',\n",
    "                c='black',\n",
    "                label='centroids')\n",
    "\n",
    "    plt.legend(scatterpoints=1)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using elbow method to determine k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Load the dataset from file\n",
    "    df = pd.read_csv(\n",
    "        \"/home/nyangweso/Desktop/Ds_1/Machine-Learning-Projects/fun_tutorials/lab1b (1)/lab1b/lab1bsamples_large.csv\", header=None)\n",
    "    df.tail()\n",
    "    print(df.tail())\n",
    "\n",
    "    # get all of the points from the dataset as an array of 2-dimensional vectors\n",
    "    X = df.iloc[:].values\n",
    "\n",
    "    # Value that you want to adjust\n",
    "    num_clusters = 4\n",
    "\n",
    "    # perform_k_means_clustering(X, num_clusters)\n",
    "\n",
    "    elbow_method_plot(X)\n",
    "\n",
    "    print(\"Number of clusters is '{}'\".format(num_clusters))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Load the dataset from file\n",
    "    df = pd.read_csv(\n",
    "        \"lab1bsamples_large.csv\", header=None)\n",
    "    df.tail()\n",
    "    print(df.tail())\n",
    "\n",
    "    # get all of the points from the dataset as an array of 2-dimensional vectors\n",
    "    X = df.iloc[:].values\n",
    "\n",
    "    # Value that you want to adjust\n",
    "    num_clusters = 4\n",
    "\n",
    "    perform_k_means_clustering(X, num_clusters)\n",
    "\n",
    "    # elbow_method_plot(X)\n",
    "\n",
    "    print(\"Number of clusters is '{}'\".format(num_clusters))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing k-means clustering with the k determined from previous cell i.e k = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Load the dataset from file\n",
    "    df = pd.read_csv(\n",
    "        \"lab1b/lab1bsamples_large.csv\", header=None)\n",
    "    df.tail()\n",
    "    print(df.tail())\n",
    "\n",
    "    # get all of the points from the dataset as an array of 2-dimensional vectors\n",
    "    X = df.iloc[:].values\n",
    "\n",
    "    # Value that you want to adjust\n",
    "    num_clusters = 15\n",
    "\n",
    "    perform_k_means_clustering(X, num_clusters)\n",
    "\n",
    "    # elbow_method_plot(X)\n",
    "\n",
    "    print(\"Number of clusters is '{}'\".format(num_clusters))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
