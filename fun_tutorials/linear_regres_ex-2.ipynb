{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regeression : In Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin with the standard imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2 * x - 5 + rng.randn(50)\n",
    "plt.scatter(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "model.fit(x[:, np.newaxis], y)\n",
    "\n",
    "xfit = np.linspace(0, 10, 1000)\n",
    "yfit = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"model slope = {model.coef_[0]}\\nmodel intercept = {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LinearRegression estimator can also handle higher dimensional models but the\\\n",
    "complexity in visualizing the model also increases as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = 10 * rng.rand(100, 3)\n",
    "y = 0.5 + np.dot(X, [1.5, -2.0, 1.0])\n",
    "\n",
    "model.fit(X, y)\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polynomial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x = np.array(\n",
    "    [\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "    ]\n",
    ")\n",
    "poly = PolynomialFeatures(3, include_bias=False)\n",
    "poly.fit_transform(x[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the transformer has converted our 1D array into a 3D array by taking the exponent of each value.\\\n",
    "We can then plug the new higher dimensional model into a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "poly_model = make_pipeline(PolynomialFeatures(7), LinearRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = np.sin(x) + 0.1 * rng.randn(50)\n",
    "\n",
    "poly_model.fit(x[:, np.newaxis], y)\n",
    "xfit = np.linspace(0, 10, 1000)\n",
    "yfit = poly_model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian basis functions\n",
    "Since they are not built into sklearn, let's create our own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class GaussianFeatures(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    \"\"\"Uniformly spaced Gaussian features for one-dimensional input\"\"\"\n",
    "\n",
    "    def __init__(self, N, width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "\n",
    "    @staticmethod\n",
    "    def _gauss_basis(x, y, width, axis=None):\n",
    "        arg = (x - y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg**2, axis))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # create N centers spread along the data range\n",
    "        self.centers_ = np.linspace(X.min(), X.max(), self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._gauss_basis(\n",
    "            X[:, :, np.newaxis], self.centers_, self.width_, axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_model = make_pipeline(GaussianFeatures(20), LinearRegression())\n",
    "\n",
    "gauss_model.fit(x[:, np.newaxis], y)\n",
    "yfit = gauss_model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit)\n",
    "plt.xlim(0, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization\n",
    "The use of basis functions can quickly lead to overfitting e.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(GaussianFeatures(30), LinearRegression())\n",
    "\n",
    "model.fit(x[:, np.newaxis], y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, model.predict(xfit[:, np.newaxis]))\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-1.5, 1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model becomes too much flexible and even goes to extreme values between locations where it is constrained by data.\\\n",
    "We can see the reason for this if we plot the coefficients of the Gaussian bases in respect to their locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_plot(model, title=None):\n",
    "    fig, ax = plt.subplots(2, sharex=True)\n",
    "    model.fit(x[:, np.newaxis], y)\n",
    "    ax[0].scatter(x, y)\n",
    "    ax[0].plot(xfit, model.predict(xfit[:, np.newaxis]))\n",
    "    ax[0].set(xlabel=\"x\", ylabel=\"y\", ylim=(-1.5, 1.5))\n",
    "\n",
    "    if title:\n",
    "        ax[0].set_title(title)\n",
    "\n",
    "    ax[1].plot(model.steps[0][1].centers_, model.steps[1][1].coef_)\n",
    "    ax[1].set(xlabel=\"basis location\", ylabel=\"coefficient\", xlim=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(GaussianFeatures(30), LinearRegression())\n",
    "\n",
    "basis_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Ridge regression (Tikhonov regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model =  make_pipeline(GaussianFeatures(30), Ridge(alpha=0.1))\n",
    "\n",
    "basis_plot(model, title='Ridge regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model =  make_pipeline(GaussianFeatures(30), Lasso(alpha=0.001))\n",
    "\n",
    "basis_plot(model, title='Ridge regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both(and generally all) types of regularization, the knob 'alpha' which decides the strength of the penalty\\\n",
    "should be determined by validation techniques e.g Cross-Validation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
